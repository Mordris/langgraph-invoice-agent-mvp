services:
  # Database: Postgres 17 + pgvector + pgvectorscale
  db:
    image: timescale/timescaledb-ha:pg17
    container_name: invoice_db
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/home/postgres/pgdata/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: always

  # Redis: State management & Rate limiting
  redis:
    image: redis/redis-stack:latest
    container_name: invoice_redis
    ports:
      - "6379:6379"
      - "8001:8001" # Redis Insight UI
    volumes:
      - redisdata:/data
    restart: always

  # Backend: LangGraph API
  backend:
    build: ./backend
    container_name: invoice_backend
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
      - REDIS_URL=${REDIS_URL}
      - MAX_TOKENS_PER_EXEC=${MAX_TOKENS_PER_EXEC}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_started
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app # Hot reload for dev

  # Frontend: Chatbot UI
  frontend:
    build: ./frontend
    container_name: invoice_frontend
    environment:
      - BACKEND_URL=http://backend:8000
    ports:
      - "8501:8501"
    depends_on:
      - backend
    volumes:
      - ./frontend:/app # Hot reload for dev

  # Ingestion: One-off data seeder
  ingestion:
    build: ./ingestion
    container_name: invoice_ingestion
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@db:5432/${POSTGRES_DB}
    depends_on:
      db:
        condition: service_healthy
    # We will run this manually or it runs on startup
    command: python ingest.py

volumes:
  pgdata:
  redisdata:
